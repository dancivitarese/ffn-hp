{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This code is an example of how to create a dataset for the FFN training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from rockml.data.adapter import Datum\n",
    "from rockml.data.adapter.seismic.segy.poststack import PostStackAdapter2D, PostStackDatum\n",
    "from rockml.data.pipeline import Pipeline\n",
    "from rockml.data.sampling import split_dataset\n",
    "from rockml.data.transformations import Composer, Transformation\n",
    "from rockml.data.transformations.seismic import image\n",
    "from rockml.data.array_ops import crop_2d\n",
    "\n",
    "from rockml_console.utils.io import makedir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'range_inlines': [100, 750],\n 'range_crosslines': [300, 1250],\n 'num_inlines': 651,\n 'num_crosslines': 951,\n 'range_time_depth': [0, 1848.0],\n 'num_time_depth': 463,\n 'res_inline': 1,\n 'res_crossline': 1,\n 'res_time_depth': 4.0,\n 'range_x': [6054167, 6295763],\n 'range_y': [60735564, 60904632]}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "params = dict()\n",
    "params['output_path'] = '/Users/sallesd/Projects/f3_ffn_db'\n",
    "params['segy_info'] = yaml.safe_load(\n",
    "    open('/Users/sallesd/Projects/f3_info/info.yml')\n",
    ")\n",
    "params['train_slices'] = yaml.safe_load(\n",
    "    open('/Users/sallesd/Projects/train_80.yml')\n",
    ")\n",
    "params['test_slices'] = yaml.safe_load(\n",
    "    open('/Users/sallesd/Projects/test.yml')\n",
    ")\n",
    "params['tile_shape'] = (64, 64)\n",
    "params['stride_shape'] = (8, 8)\n",
    "params['gray_levels'] = 256\n",
    "params['crop'] = (0, 0, 75, 0)\n",
    "params['percentile'] = 5.0\n",
    "params['valid_ratio'] = 0.1\n",
    "params['cores'] = 8\n",
    "\n",
    "params['horizons_path_list'] = [\n",
    "    line['path'] for line in params['segy_info']['horizon_pixel_ranges']\n",
    "]\n",
    "makedir(params['output_path'])\n",
    "\n",
    "adapter = PostStackAdapter2D(\n",
    "    segy_path=params['segy_info']['segy_path'],\n",
    "    horizons_path_list=params['horizons_path_list'],\n",
    "    data_dict=params['train_slices']\n",
    ")\n",
    "adapter.initial_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Lambda(Transformation):\n",
    "    def __init__(self, function: Callable[[Datum], Datum], **kwargs):\n",
    "        self.function = function\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, dataset: Datum) -> Datum:\n",
    "        return self.function(dataset, **self.kwargs)\n",
    "\n",
    "def filter_centered_tiles(datum: PostStackDatum) -> PostStackDatum:\n",
    "    allow = 2\n",
    "    vcrop = datum.label.shape[0] // 2 - allow\n",
    "    hcrop = datum.label.shape[1] // 2 - allow\n",
    "    if np.sum(datum.label[vcrop:-vcrop, hcrop:-hcrop]) != 0:\n",
    "        return datum\n",
    "\n",
    "\n",
    "def merge_feat_centered_label(datum: PostStackDatum,\n",
    "                              l_crop: int = 0,\n",
    "                              r_crop: int = 0,\n",
    "                              t_crop: int = 0,\n",
    "                              b_crop: int = 0) -> PostStackDatum:\n",
    "    assert datum.features.shape[:-1] == datum.label.shape\n",
    "\n",
    "    b_idx = datum.label.shape[0] - b_crop\n",
    "    r_idx = datum.label.shape[1] - r_crop\n",
    "    new_feat = np.zeros(datum.label.shape, dtype=np.float32)\n",
    "    new_feat[t_crop:b_idx, l_crop:r_idx] += crop_2d(datum.label, t_crop, b_crop, l_crop, r_crop)\n",
    "    new_feat = np.expand_dims(new_feat, axis=-1)\n",
    "    datum.features = np.squeeze(np.stack((datum.features, new_feat), axis=-1))\n",
    "    return datum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the transformation composition for the first dataset. This dataset contains\n",
    "features with only the central information of the label. We use such a dataset to train\n",
    "our model for a few epochs. We call this dataset as DB01."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pre_proc = [\n",
    "    image.Crop2D(\n",
    "        crop_left=params['crop'][0],\n",
    "        crop_right=params['crop'][1],\n",
    "        crop_top=params['crop'][2],\n",
    "        crop_bottom=params['crop'][3]\n",
    "    ),\n",
    "    image.ScaleIntensity(\n",
    "        gray_levels=params['gray_levels'],\n",
    "        percentile=params['percentile']\n",
    "    ),\n",
    "    image.BinarizeMask(),\n",
    "    image.ThickenLinesMask(n_points=1),\n",
    "    image.ViewAsWindows(\n",
    "        tile_shape=params['tile_shape'],\n",
    "        stride_shape=params['stride_shape']\n",
    "    ),\n",
    "    Lambda(function=filter_centered_tiles),\n",
    "    Lambda(\n",
    "        function=merge_feat_centered_label,\n",
    "        l_crop=params['tile_shape'][0] // 2 - 5,\n",
    "        r_crop=params['tile_shape'][0] // 2 - 5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "composer = Composer(transformations=pre_proc)\n",
    "pipeline = Pipeline(composer=composer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tiles = pipeline.build_dataset(\n",
    "    data_adapter=adapter,\n",
    "    num_blocks=params['cores'],\n",
    "    cores=params['cores']\n",
    ")\n",
    "num_classes = len(np.unique([t.label for t in tiles]))\n",
    "\n",
    "# Getting validation set from the training tiles\n",
    "train_tiles, valid_tiles = split_dataset(\n",
    "    dataset=tiles,\n",
    "    valid_ratio=params['valid_ratio']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray((train_tiles[234].label * 250).astype(np.uint8)).show()\n",
    "Image.fromarray((train_tiles[234].features[:, :, 0]).astype(np.uint8)).show()\n",
    "Image.fromarray((train_tiles[234].features[:, :, 1] * 250).astype(np.uint8)).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
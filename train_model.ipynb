{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.model_zoo import unet_tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "params = dict()\n",
    "params['train_db01_path'] = '/Users/sallesd/Projects/f3_ffn_db/train_db01.hdf'\n",
    "params['test_db01_path'] = '/Users/sallesd/Projects/f3_ffn_db/valid_db01.hdf'\n",
    "params['train_db02_path'] = '/Users/sallesd/Projects/f3_ffn_db/train_db02.hdf'\n",
    "params['test_db02_path'] = '/Users/sallesd/Projects/f3_ffn_db/valid_db02.hdf'\n",
    "params['model_path'] = '/Users/sallesd/Projects/f3_ffn_model'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MeanIoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='mean_iou', **kwargs):\n",
    "        super(MeanIoU, self).__init__(name=name, **kwargs)\n",
    "        self.tf_mean_iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "        self.tf_mean_iou.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        return self.tf_mean_iou.result()\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.tf_mean_iou.reset_states()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def training_loop(train_dataset: tf.data.Dataset,\n",
    "                  val_dataset: tf.data.Dataset,\n",
    "                  model: tf.keras.Model,\n",
    "                  model_path: str,\n",
    "                  optimizer: tf.keras.optimizers.Optimizer,\n",
    "                  loss_fn: tf.keras.losses.Loss,\n",
    "                  metrics: Tuple[dict, dict],\n",
    "                  epochs: int):\n",
    "    train_metrics = metrics[0]\n",
    "    val_metrics = metrics[1]\n",
    "\n",
    "    # Iterate over epochs.\n",
    "    best = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "        epoch_loss = 0\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x_batch_train)\n",
    "                pixel_loss = loss_fn(y_batch_train, logits)\n",
    "                w = y_batch_train[:, :, :, -1] * 9\n",
    "                w = w + y_batch_train[:, :, :, 0]\n",
    "                pixel_loss *= w\n",
    "                loss_value = tf.reduce_sum(pixel_loss) * (\n",
    "                        1. / y_batch_train.shape[0] / y_batch_train.shape[1] / y_batch_train.shape[2])\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            epoch_loss += loss_value\n",
    "\n",
    "            # Update training metric.\n",
    "            for metric in train_metrics.values():\n",
    "                metric(y_batch_train, logits)\n",
    "\n",
    "            # Log every 2 batches.\n",
    "            if step % 2 == 0:\n",
    "                print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
    "                print('Seen so far: %s samples' % ((step + 1) * x_batch_train.shape[0]))\n",
    "\n",
    "        print(f'Epoch loss: {epoch_loss / (step + 1)}')\n",
    "        # Display metrics at the end of each epoch.\n",
    "        for metric_name, metric in train_metrics.items():\n",
    "            print(f\"| {metric_name}: {metric.result()} \", end=\"\", flush=True)\n",
    "            metric.reset_states()\n",
    "        print(\"|\")\n",
    "\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            val_logits = model(x_batch_val)\n",
    "            for metric in val_metrics.values():\n",
    "                metric(y_batch_val, val_logits)\n",
    "\n",
    "        metric_dict = {}\n",
    "        for metric_name, metric in val_metrics.items():\n",
    "            metric_dict[metric_name] = metric.result().numpy()\n",
    "            print(f'| {metric_name}: {metric_dict[metric_name]} ', end='', flush=True)\n",
    "            metric.reset_states()\n",
    "        print(\"|\")\n",
    "        # print('Validation acc: %s' % (float(val_acc),))\n",
    "\n",
    "        if best < metric_dict[metric_name]:\n",
    "            model.save(f'{model_path}_best.h5')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with h5py.File(params['train_db01_path'], 'r') as train_h5_file:\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (np.array(train_h5_file.get('features')),\n",
    "         np.array(train_h5_file.get('label')))\n",
    "    )\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10192).batch(batch_size=2048)\n",
    "\n",
    "with h5py.File(params['test_db01_path'], 'r') as test_h5_file:\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (np.array(test_h5_file.get('features')),\n",
    "         np.array(test_h5_file.get('label')))\n",
    "    )\n",
    "    test_dataset = test_dataset.batch(batch_size=512)\n",
    "\n",
    "input_shape = (64, 64, 2)\n",
    "num_classes_output = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_metrics = {\n",
    "    'train_mean_iou': MeanIoU(),\n",
    "    'train_cat_acc': tf.keras.metrics.CategoricalAccuracy()\n",
    "}\n",
    "val_metrics = {\n",
    "    'val_mean_iou': MeanIoU(),\n",
    "    'val_cat_acc': tf.keras.metrics.CategoricalAccuracy()\n",
    "}\n",
    "\n",
    "model = training_loop(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=test_dataset,\n",
    "    model=unet_tf2(input_shape=input_shape, output_channels=num_classes_output),\n",
    "    model_path=params['model_path'],\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE),\n",
    "    metrics=(train_metrics, val_metrics),\n",
    "    epochs=5)\n",
    "model.save(f\"{params['model_path']}.h5\")\n",
    "\n",
    "print(f\"Total training time: {time.time() - start}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}